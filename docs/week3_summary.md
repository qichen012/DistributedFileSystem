# 第三周项目总结

## 一、本周目标
在前两周已经实现了文件切块、上传/下载、存储节点注册与调度器动态获取节点的功能后，本周的目标是：
1. 为存储节点增加健康检查接口；
2. 在调度器中实现只选择健康节点的功能；
3. 支持多副本存储机制，提高容错能力；
4. 下载时支持从多个副本中选择可用节点，保证可用性；
5. 编写并执行异常场景下的测试。

---

## 二、完成情况

### 1. 健康检查接口
- 在 `storage_nodes/node.py` 中新增 `GET /health`，返回节点在线状态。
- 在调度器中调用该接口，过滤掉不在线的节点，保证上传/下载任务不会分配到不可用节点。

### 2. 多副本存储
- 在 `client/client_api.py` 的 `upload_file` 中实现了副本机制：
  - 每个文件块可以被存储在多个不同的存储节点上（本周设置为 2 个副本）。
  - 在元数据数据库的 `chunks` 表中会有多条记录指向同一个 `file_id + chunk_index`。

### 3. 容错下载
- 在 `download_file` 中实现了多副本容错逻辑：
  - 下载时会从多个候选节点依次尝试；
  - 如果某个节点不可用，会自动切换到下一个副本节点；
  - 保证即使部分节点宕机，文件也能被完整恢复。

### 4. 异常场景测试
- 测试步骤：
  1. 启动 2 个存储节点（9001、9002）。
  2. 上传文件，设置副本数为 2。
  3. 手动关闭其中一个节点。
  4. 执行下载，验证文件仍能完整恢复。
- 测试结果：文件下载成功，验证副本机制和容错逻辑有效。

---

## 三、问题与解决
- **问题 1**：上传时如何保证副本分布在不同节点？  
  **解决**：通过调度器的节点列表按索引轮询选择节点，避免重复。
- **问题 2**：下载时如何处理失败的副本？  
  **解决**：在 `download_file` 中增加 `try/except`，逐个尝试候选节点。

---

## 四、收获
- 初步实现了 **高可用机制**，系统具备一定的容错能力；
- 学会了在分布式环境中通过 **副本机制** 提升数据可靠性；
- 掌握了健康检查与调度器结合的基本思路；
- 项目从“能用”迈向“更可靠”的阶段。

---
